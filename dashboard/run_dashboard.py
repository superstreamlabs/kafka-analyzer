#!/usr/bin/env python3
"""
Kafka Dashboard Launcher
Run this to start the interactive Kafka monitoring dashboard
"""

import os
import sys
import argparse
import subprocess
from pathlib import Path


def check_dependencies():
    """Check if required Python packages are installed"""
    required_packages = [
        'dash', 'plotly', 'pandas', 'numpy', 'dash_bootstrap_components'
    ]
    
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print("âŒ Missing required packages:")
        for package in missing_packages:
            print(f"   - {package}")
        print("\nğŸ’¡ Install missing packages with:")
        print("   pip install -r requirements.txt")
        return False
    
    return True


def find_data_directory():
    """Find the kafka-analysis directory"""
    current_dir = Path.cwd()
    
    # Common locations to check
    possible_paths = [
        current_dir / "kafka-analysis",
        current_dir / ".." / "kafka-analysis",
        current_dir / ".." / ".." / "kafka-analysis",
        Path.home() / "kafka-analysis"
    ]
    
    for path in possible_paths:
        if path.exists() and path.is_dir():
            return str(path)
    
    return None


def check_analysis_files(data_dir):
    """Check if analysis files exist in the data directory"""
    if not data_dir or not os.path.exists(data_dir):
        return False, []
    
    json_files = []
    for file in os.listdir(data_dir):
        if file.startswith('kafka-analysis-') and file.endswith('.json'):
            json_files.append(file)
    
    return len(json_files) > 0, json_files


def install_dependencies():
    """Install required dependencies"""
    print("ğŸ“¦ Installing required dependencies...")
    try:
        subprocess.check_call([
            sys.executable, "-m", "pip", "install", "-r", "requirements.txt"
        ])
        print("âœ… Dependencies installed successfully!")
        return True
    except subprocess.CalledProcessError:
        print("âŒ Failed to install dependencies")
        return False


def main():
    parser = argparse.ArgumentParser(
        description='Kafka Cluster Dashboard',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python run_dashboard.py                          # Run with auto-detected data directory
  python run_dashboard.py --data-dir ./reports    # Use custom data directory
  python run_dashboard.py --port 8080             # Run on different port
  python run_dashboard.py --install               # Install dependencies first
        """
    )
    
    parser.add_argument('--data-dir', 
                       help='Directory containing Kafka analysis reports')
    parser.add_argument('--port', type=int, default=8050,
                       help='Port to run dashboard on (default: 8050)')
    parser.add_argument('--host', default='127.0.0.1',
                       help='Host to bind to (default: 127.0.0.1)')
    parser.add_argument('--debug', action='store_true',
                       help='Run in debug mode')
    parser.add_argument('--install', action='store_true',
                       help='Install required dependencies first')
    
    args = parser.parse_args()
    
    # Change to dashboard directory
    dashboard_dir = Path(__file__).parent
    os.chdir(dashboard_dir)
    
    # Install dependencies if requested
    if args.install:
        if not install_dependencies():
            sys.exit(1)
    
    # Check dependencies
    if not check_dependencies():
        print("\nğŸ’¡ Run with --install flag to install dependencies automatically:")
        print("   python run_dashboard.py --install")
        sys.exit(1)
    
    # Determine data directory
    if args.data_dir:
        data_dir = args.data_dir
    else:
        data_dir = find_data_directory()
        if not data_dir:
            data_dir = "../kafka-analysis"  # Default fallback
    
    # Check for analysis files
    has_files, json_files = check_analysis_files(data_dir)
    
    print("ğŸš€ Kafka Dashboard Launcher")
    print("=" * 40)
    print(f"ğŸ“ Data directory: {os.path.abspath(data_dir)}")
    
    if not has_files:
        print("\nâš ï¸  No analysis files found!")
        print("ğŸ’¡ To generate analysis reports, run:")
        print("   cd /path/to/kafka-analyzer")
        print("   npx superstream-kafka-analyzer --config config.json")
        print("\nğŸ“ The dashboard will still start but show 'No data available'")
    else:
        print(f"âœ… Found {len(json_files)} analysis file(s)")
        print(f"ğŸ“„ Latest: {max(json_files, key=lambda x: os.path.getmtime(os.path.join(data_dir, x)))}")
    
    print(f"\nğŸŒ Starting dashboard on http://{args.host}:{args.port}")
    print("âš¡ Dashboard will auto-refresh every 30 seconds")
    print("ğŸ”„ Click 'Refresh Now' button to manually refresh")
    print("\nğŸ“Š Dashboard Features:")
    print("   â€¢ Real-time cluster health monitoring")
    print("   â€¢ Interactive charts and metrics")
    print("   â€¢ Health checks analysis")
    print("   â€¢ Topics and consumer groups overview")
    print("   â€¢ Historical trend analysis")
    
    try:
        # Import and run dashboard
        from app import KafkaDashboard
        
        dashboard = KafkaDashboard(data_dir=data_dir)
        dashboard.run(debug=args.debug, port=args.port, host=args.host)
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Dashboard stopped by user")
    except Exception as e:
        print(f"\nâŒ Error starting dashboard: {e}")
        print("ğŸ’¡ Try running with --debug flag for more details")
        sys.exit(1)


if __name__ == "__main__":
    main()
